# 引言

语言是人类表达和交流的突出能力，它在儿童早期发展并在一生中不断演变 [1, 2]。然而，机器除非配备了强大的人工智能算法，否则不能自然地掌握以人类语言形式理解和交
流的能力。实现让机器像人类一样阅读、写作和交流的目标，一直是一个长期的研究挑战 [3]。从技术上讲，语言建模（LM）是提高机器语言智能的主要方法之一。一般来说，LM 旨在对词序列的生成概率进行建模，以预测未来（或缺失）tokens 的概率。语言建模的研究在文献中受到了广泛关注，可以分为四个主要发展阶段：

- 统计语言模型 (SLM)： SLMs [4–7] 基于统计学习方法开发，并在 20 世纪 90 年代兴起。其基本思想是基于马尔可夫假设建立词预测模型，例如根据最近的上下文预测下一个词。具有固定上下文长度 n 的 SLM 也称为 n 元语言模型，例如 bigram 和 trigram 语言模型。SLM 已被广泛应用于提高信息检索（IR） [8, 9] 和自然语言处理（NLP） [10–12] 的任务性能。然而，它们通常受到维数灾难的困扰：由于需要估计指数
